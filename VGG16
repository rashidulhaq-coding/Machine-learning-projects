{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6961629,"sourceType":"datasetVersion","datasetId":3999173}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rashidulhaqyousafzai/vgg16?scriptVersionId=192899680\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Vgg_Conv_block(no_of_layers,no_of_filters,x):\n    \n    for layer in range(no_of_layers):\n        x = layers.Conv2D(no_of_filters,3,activation='relu')(x)\n    x = layers.MaxPool2D(strides=2)(x)\n    \n    return x\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-16T17:52:03.133071Z","iopub.execute_input":"2024-08-16T17:52:03.133602Z","iopub.status.idle":"2024-08-16T17:52:03.138946Z","shell.execute_reply.started":"2024-08-16T17:52:03.133574Z","shell.execute_reply":"2024-08-16T17:52:03.137866Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model_input = layers.Input(shape=(224,224,3))\n\nx = Vgg_Conv_block(2,64,model_input)\nx = Vgg_Conv_block(2,128,x)\nx = Vgg_Conv_block(2,256,x)\nx = Vgg_Conv_block(3,512,x)\nx = Vgg_Conv_block(3,512,x)\nx = layers.GlobalAveragePooling2D()(x)\nx  = layers.Dense(4096,activation='relu')(x)\nx  = layers.Dense(4096,activation='relu')(x)\n\nx  = layers.Dense(45,activation='softmax')(x)\n\nmodel = Model(model_input, x,name='VGG-16')","metadata":{"execution":{"iopub.status.busy":"2024-08-16T17:52:03.140149Z","iopub.execute_input":"2024-08-16T17:52:03.140478Z","iopub.status.idle":"2024-08-16T17:52:03.919472Z","shell.execute_reply.started":"2024-08-16T17:52:03.140447Z","shell.execute_reply":"2024-08-16T17:52:03.918715Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n# Initialize the ImageDataGenerator with common augmentation techniques\ndatagen = ImageDataGenerator(\n    rotation_range=20,  # Random rotation between 0 and 180 degrees\n    width_shift_range=0.2,  # Random shift in width by up to 20%\n    height_shift_range=0.2,  # Random shift in height by up to 20%\n    shear_range=0.2,  # Shear transformation range\n    zoom_range=0.2,  # Zoom range\n    horizontal_flip=True,  # Flip horizontally with 50% probability\n    vertical_flip=True,  # Flip vertically with 50% probability\n    fill_mode='nearest', # Fill mode for filling holes left after transformations\n    rescale=1./255, \n    validation_split=0.2\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T17:52:03.921185Z","iopub.execute_input":"2024-08-16T17:52:03.92147Z","iopub.status.idle":"2024-08-16T17:52:03.927592Z","shell.execute_reply.started":"2024-08-16T17:52:03.921446Z","shell.execute_reply":"2024-08-16T17:52:03.926679Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"directory = '/kaggle/input/mammals-image-classification-dataset-45-animals/mammals'\ntrain_data = datagen.flow_from_directory(directory,\n    target_size= (224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=64,\n    shuffle=True,\n    subset=\"training\"\n    )\n\nval_data = datagen.flow_from_directory(directory,\n    target_size= (224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=128,\n    shuffle=True,\n    subset=\"validation\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-16T17:52:03.928969Z","iopub.execute_input":"2024-08-16T17:52:03.929829Z","iopub.status.idle":"2024-08-16T17:52:04.598092Z","shell.execute_reply.started":"2024-08-16T17:52:03.929795Z","shell.execute_reply":"2024-08-16T17:52:04.59716Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 11020 images belonging to 45 classes.\nFound 2731 images belonging to 45 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy',tf.keras.metrics.F1Score()])","metadata":{"execution":{"iopub.status.busy":"2024-08-16T17:52:04.599339Z","iopub.execute_input":"2024-08-16T17:52:04.599634Z","iopub.status.idle":"2024-08-16T17:52:04.613825Z","shell.execute_reply.started":"2024-08-16T17:52:04.599609Z","shell.execute_reply":"2024-08-16T17:52:04.612881Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model.fit(train_data,validation_data=val_data,epochs=2)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T17:52:04.614959Z","iopub.execute_input":"2024-08-16T17:52:04.61525Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1723830802.037351     107 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1723830802.066393     107 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0209 - f1_score: 0.0069 - loss: 3.8417","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1723831044.507739     104 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 2s/step - accuracy: 0.0209 - f1_score: 0.0069 - loss: 3.8417 - val_accuracy: 0.0256 - val_f1_score: 0.0011 - val_loss: 3.8236\nEpoch 2/2\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1723831100.318398     107 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889ms/step - accuracy: 0.0288 - f1_score: 0.0036 - loss: 3.8056","output_type":"stream"}]}]}